{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On collaboration in mathematical oncology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# List of input files and their corresponding output names\n",
    "files_to_process = [\n",
    "    (\"ALL_math_onco.txt\", \"math_onco_number_authors_with_mean.csv\"),\n",
    "    (\"ALL_math_bio_without_onco.txt\", \"math_bio_without_onco_number_authors_with_mean.csv\")\n",
    "]\n",
    "\n",
    "def process_file(input_file, output_file):\n",
    "    print(f\"ðŸ” Processing {input_file}...\")\n",
    "    year_author_counts = defaultdict(lambda: defaultdict(int))\n",
    "    max_author_count = 0\n",
    "    author_blocks = defaultdict(list)  # Store full entries by author count (PT J to ER)\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        current_entry = None\n",
    "        entry_lines = [] #all lines PT J to ER\n",
    "\n",
    "        for line in file: #for each line \n",
    "            if line.startswith(\"PT \"): # each article starts with PT J\n",
    "                current_entry = {\"PY\": None, \"AU_count\": 0}\n",
    "                entry_lines = [line]\n",
    "            elif current_entry is not None:\n",
    "                entry_lines.append(line)\n",
    "                if line.startswith(\"PY \"): #store PY \n",
    "                    current_entry[\"PY\"] = line[3:].strip()\n",
    "                elif line.startswith(\"AU \"): #if we find an AU entry\n",
    "                    authors_line = line[3:].strip() # looks at everything in AU line\n",
    "                    authors_line = \" \".join(authors_line.split()) #removes irregular spacing\n",
    "                    authors = authors_line.split() # splits line by spaces so just names in file\n",
    "                    current_entry[\"AU_count\"] = len(authors) // 2 #each author is represented by 2 elements so divide number of words by 2\n",
    "                    #authors_line = line[3:].strip()\n",
    "                    #current_entry[\"AU_count\"] = authors_line.count(',') + authors_line.count(';')\n",
    "                elif line.startswith(\"ER\"): #end of record ER\n",
    "                    if current_entry[\"PY\"] is not None:\n",
    "                        year = current_entry[\"PY\"]\n",
    "                        author_count = current_entry[\"AU_count\"]\n",
    "                        year_author_counts[year][author_count] += 1\n",
    "                        max_author_count = max(max_author_count, author_count)\n",
    "                        author_blocks[author_count].append(\"\".join(entry_lines))\n",
    "                    current_entry = None\n",
    "                    entry_lines = []\n",
    "\n",
    "    # Create CSV summary\n",
    "    fieldnames = [\"Year\"] + [f\"author_{i}\" for i in range(1, max_author_count + 1)] + [\"mean_authors\"]\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for year, author_counts in sorted(year_author_counts.items()):\n",
    "            row = {\"Year\": year}\n",
    "            total_articles = 0\n",
    "            total_authors = 0\n",
    "\n",
    "            for i in range(1, max_author_count + 1):\n",
    "                count = author_counts.get(i, 0)\n",
    "                row[f\"author_{i}\"] = count\n",
    "                total_articles += count\n",
    "                total_authors += i * count\n",
    "\n",
    "            row[\"mean_authors\"] = round(total_authors / total_articles, 2) if total_articles > 0 else 0\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"âœ… Results written to {output_file}\")\n",
    "\n",
    "    # Write author count-specific .txt files\n",
    "    base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    output_dir = f\"{base_name}_author_groups\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for count, entries in author_blocks.items():\n",
    "        label = f\"{count}_author.txt\" if count == 1 else f\"{count}_authors.txt\"\n",
    "        out_path = os.path.join(output_dir, label)\n",
    "        with open(out_path, 'w', encoding='utf-8') as out_file:\n",
    "            for block in entries:\n",
    "                out_file.write(block + \"\\n\")\n",
    "        print(f\"ðŸ“„ Saved {len(entries)} entries to {out_path}\")\n",
    "\n",
    "# Run the processor\n",
    "for input_file, output_file in files_to_process:\n",
    "    process_file(input_file, output_file)\n",
    "\n",
    "print(\"\\nðŸŽ‰ All files processed with full author count distribution, mean counts, and separate author group files!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to process one input file into high and low citation files\n",
    "def process_articles_by_year(\n",
    "    input_file,  # input file\n",
    "    high_citations_file,  # output file of higher than average cited articles\n",
    "    low_citations_file  # output file of lower than average cited articles\n",
    "):\n",
    "\n",
    "    # Read the entire file content\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()  # puts file into string called content\n",
    "\n",
    "    # Split the content into individual articles\n",
    "    articles = re.findall(r'(PT J.*?\\nER\\n)', content, re.DOTALL)  # articles start with PT J and end with ER\n",
    "\n",
    "    # First pass: Group TC values by year\n",
    "    year_tc_values = defaultdict(list)  # creates dictionary where keys are years and values are TC values\n",
    "\n",
    "    for article in articles:  # loops through all articles\n",
    "        year_match = re.search(r'PY (\\d{4})', article)  # extracts the publication year\n",
    "        tc_match = re.search(r'TC (\\d+)', article)  # extracts the citation count\n",
    "\n",
    "        if year_match:  # appends each article's TC to corresponding year\n",
    "            year = year_match.group(1)\n",
    "            tc = int(tc_match.group(1)) if tc_match else 0\n",
    "            year_tc_values[year].append(tc)\n",
    "\n",
    "    # Compute per-year mean TC\n",
    "    year_mean_tc = {\n",
    "        year: sum(tcs) / len(tcs) if tcs else 0  # calculate mean for each year\n",
    "        for year, tcs in year_tc_values.items()\n",
    "    }\n",
    "\n",
    "    # Print per-year mean TC values\n",
    "    for year in sorted(year_mean_tc.keys()):\n",
    "        print(f\"ðŸ“Š Year {year} - Mean TC: {year_mean_tc[year]:.2f}\")\n",
    "\n",
    "    # Second pass: Write articles to respective files based on year-specific mean\n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "\n",
    "    with open(high_citations_file, 'w', encoding='utf-8') as high_f, \\\n",
    "         open(low_citations_file, 'w', encoding='utf-8') as low_f:\n",
    "\n",
    "        for article in articles:  # loop over articles\n",
    "            year_match = re.search(r'PY (\\d{4})', article)  # extract publication year\n",
    "            tc_match = re.search(r'TC (\\d+)', article)  # extract total citations\n",
    "\n",
    "            if year_match:\n",
    "                year = year_match.group(1)\n",
    "                tc = int(tc_match.group(1)) if tc_match else 0\n",
    "                mean_tc = year_mean_tc.get(year, 0)  # get the mean for that year\n",
    "\n",
    "                if tc >= mean_tc:  # if greater than or equal to mean, write to high citation file\n",
    "                    high_f.write(article + '\\n')\n",
    "                    high_count += 1\n",
    "                else:  # otherwise write to low citation file\n",
    "                    low_f.write(article + '\\n')\n",
    "                    low_count += 1\n",
    "\n",
    "    # Print summary for this file\n",
    "    print(f\"\\nâœ… Finished processing {input_file}\")\n",
    "    print(f\"ðŸŸ¥ Articles with TC â‰¥ year mean: {high_count}\")\n",
    "    print(f\"ðŸŸ© Articles with TC < year mean: {low_count}\")\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# ---------- Process BOTH files ----------\n",
    "\n",
    "# Process ALL_math_onco.txt\n",
    "process_articles_by_year(\n",
    "    input_file=\"ALL_math_onco.txt\",\n",
    "    high_citations_file=\"ALL_math_onco_high_citations.txt\",\n",
    "    low_citations_file=\"ALL_math_onco_low_citations.txt\"\n",
    ")\n",
    "\n",
    "# Process ALL_math_bio_without_onco.txt\n",
    "process_articles_by_year(\n",
    "    input_file=\"ALL_math_bio_without_onco.txt\",\n",
    "    high_citations_file=\"ALL_math_bio_without_onco_high_citations.txt\",\n",
    "    low_citations_file=\"ALL_math_bio_without_onco_low_citations.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# List of input files and their corresponding output names\n",
    "files_to_process = [\n",
    "    (\"ALL_math_onco_high_citations.txt\", \"ALL_math_onco_high_citations_number_authors_with_mean.csv\"),\n",
    "    (\"ALL_math_bio_without_onco_high_citations.txt\", \"ALL_math_bio_without_onco_high_citations_number_authors_with_mean.csv\")\n",
    "]\n",
    "\n",
    "def process_file(input_file, output_file):\n",
    "    print(f\"ðŸ” Processing {input_file}...\")\n",
    "    year_author_counts = defaultdict(lambda: defaultdict(int)) # Map to each publication year\n",
    "    max_author_count = 0  # To track the highest number of authors found\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        current_entry = None\n",
    "        for line in file:\n",
    "            if line.startswith(\"PT \"): # Indicated start of article (PT J) so create a new entry\n",
    "                current_entry = {\"PY\": None, \"AU_count\": 0} # To store the year and author count\n",
    "            elif line.startswith(\"PY \") and current_entry is not None:\n",
    "                current_entry[\"PY\"] = line[3:].strip()\n",
    "            elif line.startswith(\"AU \") and current_entry is not None:\n",
    "                authors_line = line[3:].strip()\n",
    "                authors_line = \" \".join(authors_line.split())\n",
    "                authors = authors_line.split()\n",
    "                current_entry[\"AU_count\"] = len(authors) // 2  # Author names are made up of 2 names\n",
    "            elif line.startswith(\"ER\"): # End of article\n",
    "                if current_entry is not None and current_entry[\"PY\"] is not None:\n",
    "                    year = current_entry[\"PY\"]\n",
    "                    author_count = current_entry[\"AU_count\"]\n",
    "                    year_author_counts[year][author_count] += 1\n",
    "                    max_author_count = max(max_author_count, author_count)\n",
    "                    current_entry = None\n",
    "\n",
    "    # Create dynamic fieldnames based on actual max author count\n",
    "    fieldnames = [\"Year\"] + [f\"author_{i}\" for i in range(1, max_author_count + 1)] + [\"mean_authors\"]\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for year, author_counts in sorted(year_author_counts.items()):\n",
    "            row = {\"Year\": year}\n",
    "            total_articles = 0\n",
    "            total_authors = 0\n",
    "\n",
    "            for i in range(1, max_author_count + 1):\n",
    "                count = author_counts.get(i, 0)\n",
    "                row[f\"author_{i}\"] = count\n",
    "                total_articles += count\n",
    "                total_authors += i * count\n",
    "\n",
    "            row[\"mean_authors\"] = round(total_authors / total_articles, 2) if total_articles > 0 else 0\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"âœ… Results written to {output_file}\")\n",
    "\n",
    "# Run the processor\n",
    "for input_file, output_file in files_to_process:\n",
    "    process_file(input_file, output_file)\n",
    "\n",
    "print(\"\\nðŸŽ‰ All files processed with full author count distribution and mean author count!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R\n",
    "\n",
    "# ---------- Load libraries ----------\n",
    "library(tidyr)\n",
    "library(dplyr)\n",
    "library(scales)\n",
    "\n",
    "# ---------- Load and clean the first dataset (Math Onco) ----------\n",
    "data_onco <- read.csv(\"/Users/kirpu383/OneDrive - Uppsala universitet/Aim 1/Results/Collaborative/math_onco_number_authors_with_mean.csv\")\n",
    "colnames(data_onco) <- gsub(\"\\\\.\", \"_\", colnames(data_onco))  # Clean column names\n",
    "\n",
    "# ---------- Convert wide to long format for Math Onco ----------\n",
    "long_data_onco <- data_onco %>%\n",
    "  pivot_longer(cols = starts_with(\"author_\"),\n",
    "               names_to = \"author_count\",\n",
    "               names_prefix = \"author_\",\n",
    "               values_to = \"count\") %>%\n",
    "  mutate(author_count = as.integer(author_count)) %>%\n",
    "  uncount(count)\n",
    "\n",
    "# ---------- Load and clean the second dataset (Math Bio Without Onco) ----------\n",
    "data_bio <- read.csv(\"/Users/kirpu383/OneDrive - Uppsala universitet/Aim 1/Results/Collaborative/math_bio_without_onco_number_authors_with_mean.csv\")\n",
    "colnames(data_bio) <- gsub(\"\\\\.\", \"_\", colnames(data_bio))  # Clean column names\n",
    "\n",
    "# ---------- Convert wide to long format for Math Bio Without Onco ----------\n",
    "long_data_bio <- data_bio %>%\n",
    "  pivot_longer(cols = starts_with(\"author_\"),\n",
    "               names_to = \"author_count\",\n",
    "               names_prefix = \"author_\",\n",
    "               values_to = \"count\") %>%\n",
    "  mutate(author_count = as.integer(author_count)) %>%\n",
    "  uncount(count)\n",
    "\n",
    "# ---------- Load and clean the high citation dataset ----------\n",
    "mean_data_onco <- read.csv(\"/Users/kirpu383/OneDrive - Uppsala universitet/Aim 1/Results/Collaborative/ALL_math_onco_high_citations_number_authors_with_mean.csv\")\n",
    "colnames(mean_data_onco) <- gsub(\"[ .>]\", \"_\", colnames(mean_data_onco))  # Clean column names\n",
    "\n",
    "mean_data_bio <- read.csv(\"/Users/kirpu383/OneDrive - Uppsala universitet/Aim 1/Results/Collaborative/ALL_math_bio_without_onco_high_citations_number_authors_with_mean.csv\")\n",
    "colnames(mean_data_onco) <- gsub(\"[ .>]\", \"_\", colnames(mean_data_onco))  # Clean column names\n",
    "\n",
    "# ---------- Ensure 'Year' is a factor with full range ----------\n",
    "all_years <- factor(1961:2024)\n",
    "long_data_onco$Year <- factor(long_data_onco$Year, levels = levels(all_years))\n",
    "long_data_bio$Year <- factor(long_data_bio$Year, levels = levels(all_years))\n",
    "mean_data_onco$Year <- factor(mean_data_onco$Year, levels = levels(all_years))\n",
    "mean_data_bio$Year <- factor(mean_data_bio$Year, levels = levels(all_years))\n",
    "\n",
    "# ---------- Function to pad missing years ----------\n",
    "pad_missing_years <- function(data, year_levels) {\n",
    "  all_years_df <- data.frame(Year = factor(levels(year_levels), levels = levels(year_levels)))\n",
    "  padded <- merge(all_years_df, data, by = \"Year\", all.x = TRUE)\n",
    "  return(padded)\n",
    "}\n",
    "\n",
    "# ---------- Pad both datasets ----------\n",
    "long_data_onco <- pad_missing_years(long_data_onco, all_years)\n",
    "long_data_bio <- pad_missing_years(long_data_bio, all_years)\n",
    "\n",
    "# ---------- Function to extract and count outliers ----------\n",
    "get_outlier_counts <- function(expanded_data) {\n",
    "  outliers <- expanded_data %>%\n",
    "    filter(!is.na(author_count)) %>%\n",
    "    group_by(Year) %>%\n",
    "    group_modify(~ {\n",
    "      out_vals <- boxplot.stats(.x$author_count)$out\n",
    "      .x %>%\n",
    "        mutate(is_outlier = author_count %in% out_vals)\n",
    "    }) %>%\n",
    "    ungroup() %>%\n",
    "    filter(is_outlier)\n",
    "  \n",
    "  outlier_counts <- outliers %>%\n",
    "    group_by(Year, author_count) %>%\n",
    "    summarise(count = n(), .groups = \"drop\") %>%\n",
    "    mutate(\n",
    "      Year_num = as.numeric(factor(Year, levels = levels(expanded_data$Year))),\n",
    "      cex_scaled = rescale(count, to = c(0.5, 2))\n",
    "    )\n",
    "  \n",
    "  return(outlier_counts)\n",
    "}\n",
    "\n",
    "# ---------- Extract outlier dot info for both datasets ----------\n",
    "outlier_dots_onco <- get_outlier_counts(long_data_onco)\n",
    "outlier_dots_bio <- get_outlier_counts(long_data_bio)\n",
    "\n",
    "# ---------- Shared y-axis limits ----------\n",
    "combined_y_range <- range(c(long_data_onco$author_count, long_data_bio$author_count), na.rm = TRUE)\n",
    "y_limits <- c(floor(combined_y_range[1]), ceiling(combined_y_range[2]))\n",
    "\n",
    "# ---------- Define x-axis ticks: every other year ----------\n",
    "year_labels <- levels(all_years)\n",
    "x_ticks <- seq(1, length(year_labels), by = 2)\n",
    "x_labels <- year_labels[x_ticks]\n",
    "\n",
    "# ---------- Start plotting ----------\n",
    "pdf(\"/Users/kirpu383/OneDrive - Uppsala universitet/Aim 1/Results/Collaborative/BOXPLOTS_NUMBER_AUTHORS.pdf\",\n",
    "    width = 16, height = 5.33)\n",
    "\n",
    "par(mfrow = c(1, 2), mar = c(6, 4, 4, 2))\n",
    "\n",
    "# ------------------ Plot for Math Onco ------------------\n",
    "# Draw horizontal grid lines first so they appear underneath\n",
    "y_ticks <- seq(y_limits[1], y_limits[2], by = 1)\n",
    "plot(1, type = \"n\", xlim = range(x_ticks), ylim = y_limits,\n",
    "     xaxt = \"n\", yaxt = \"n\", xlab = \"\", ylab = \"\", main = \"\")\n",
    "abline(h = y_ticks, col = \"gray\", lty = \"dotted\")\n",
    "\n",
    "# Then add the actual boxplot on top\n",
    "boxplot(author_count ~ Year, data = long_data_onco,\n",
    "        add = TRUE,                     # Add to the existing blank plot\n",
    "        notch = FALSE,\n",
    "        xlab = \"Year\", ylab = \"Number of Authors\",\n",
    "        main = \"Mathematical Oncology\",\n",
    "        xaxt = \"n\", yaxt = \"n\",\n",
    "        col = \"lightgray\", border = \"black\", outline = FALSE)\n",
    "\n",
    "# Custom axes (after the boxplot)\n",
    "axis(1, at = x_ticks, labels = x_labels, las = 2)\n",
    "axis(2, at = y_ticks, las = 1)\n",
    "\n",
    "# Add mean points (full dataset)\n",
    "means_onco <- tapply(long_data_onco$author_count, long_data_onco$Year, mean, na.rm = TRUE)\n",
    "for (i in seq_along(means_onco)) {\n",
    "  if (!is.na(means_onco[i])) {\n",
    "    points(i, means_onco[i], pch = 8, col = \"turquoise1\", cex = 1)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Add red crosses for high-citation means\n",
    "for (i in seq_along(mean_data_onco$Year)) {\n",
    "  if (!is.na(mean_data_onco$mean_authors[i])) {\n",
    "    year_index <- which(levels(mean_data_onco$Year) == mean_data_onco$Year[i])\n",
    "    points(year_index, mean_data_onco$mean_authors[i], pch = 4, col = \"red\", cex = 1.5)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Add outlier dots\n",
    "points(outlier_dots_onco$Year_num, outlier_dots_onco$author_count,\n",
    "       pch = 16, col = \"black\", cex = outlier_dots_onco$cex_scaled)\n",
    "\n",
    "# ------------------ Plot for Math Bio Without Onco ------------------\n",
    "# First draw an empty plot to set up coordinate space and draw grid lines\n",
    "y_ticks <- seq(y_limits[1], y_limits[2], by = 1)\n",
    "plot(1, type = \"n\", xlim = range(x_ticks), ylim = y_limits,\n",
    "     xaxt = \"n\", yaxt = \"n\", xlab = \"\", ylab = \"\", main = \"\")\n",
    "abline(h = y_ticks, col = \"gray\", lty = \"dotted\")  # Grid lines under boxplots\n",
    "\n",
    "# Now add the boxplot on top\n",
    "boxplot(author_count ~ Year, data = long_data_bio,\n",
    "        add = TRUE,                     # Add to existing plot\n",
    "        notch = FALSE,\n",
    "        xlab = \"Year\", ylab = \"Number of Authors\",\n",
    "        main = \"Mathematical Biology excluding Mathematical Oncology\",\n",
    "        xaxt = \"n\", yaxt = \"n\", \n",
    "        col = \"gray\", border = \"black\", outline = FALSE,\n",
    "        ylim = y_limits)\n",
    "\n",
    "# Draw the axes on top of everything\n",
    "axis(1, at = x_ticks, labels = x_labels, las = 2)\n",
    "axis(2, at = y_ticks, las = 1)\n",
    "\n",
    "\n",
    "means_bio <- tapply(long_data_bio$author_count, long_data_bio$Year, mean, na.rm = TRUE)\n",
    "for (i in seq_along(means_bio)) {\n",
    "  if (!is.na(means_bio[i])) {\n",
    "    points(i, means_bio[i], pch = 8, col = \"turquoise1\", cex = 1)\n",
    "  }\n",
    "}\n",
    "\n",
    "for (i in seq_along(mean_data_bio$Year)) {\n",
    "  if (!is.na(mean_data_bio$mean_authors[i])) {\n",
    "    year_index <- which(levels(mean_data_bio$Year) == mean_data_bio$Year[i])\n",
    "    points(year_index, mean_data_bio$mean_authors[i], pch = 4, col = \"red\", cex = 1.5)\n",
    "  }\n",
    "}\n",
    "\n",
    "points(outlier_dots_bio$Year_num, outlier_dots_bio$author_count,\n",
    "       pch = 16, col = \"black\", cex = outlier_dots_bio$cex_scaled)\n",
    "\n",
    "dev.off()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "0e356716c2af146b4f1229c16fd80fd2e17e74cbf6057515b63f09e4d327206c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
